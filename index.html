<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Feeding the audio graph</title>
    <link href="https://fonts.googleapis.com/css?family=Source+Serif+Pro" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro" rel="stylesheet">
    <link href="https://cdn.rawgit.com/24ways/frontend/master/src/components/scopes/syntax/syntax.css" rel="stylesheet" />
    <style media="screen">
      :root {
        --color-year: hsl(300, 100%, 16%);
        --color-year--dark: hsl(300, 100%, 8%);
        --color-year--dark-alpha: hsla(300, 100%, 8%, 0.8);
              --color-day: hsl(304, 80%, 60%);
        --color-day--light: hsl(304, 60%, 98%);
        --color-day--dark: hsl(304, 100%, 24%);
        --color-day--dark-alpha: hsla(304, 100%, 24%, 0.33);
      }

      h1, h2, h3, h4 {
        font-family: Source Sans Pro,serif;
        color: var(--color-day--dark,#7a0000)
      }

      body {font-family: Source Serif Pro,serif;
        background-color: var(--color-day--light); color: #3f3f46; max-width: 700px; margin-bottom: 10em; padding: 2em;font-size: 1.2em;

        -moz-osx-font-smoothing: grayscale;
        -webkit-font-smoothing: antialiased;
        line-height: 1.5;

      }

      pre {
        font-family: Source Sans Pro,serif;
        background: hsla(0,0%,100%,.5); padding: 1em;
      }
    </style>
  </head>
  <body>

    <!--______ DO NOT EDIT HERE ______-->

    <h1 id="feeding-the-audio-graph">Feeding the audio graph</h1>
<p>In 2004, I was given an iPod.</p>
<p>I count this as one of the most intuitive bits of technology I&#39;ve ever owned.  It wasn&#39;t because of the the snazzy (colour!) menus or circular touchpad.  I loved how smoothly it fitted into my life. I could plug in my headphones, and listen to music while I was out and about.  Then when I got home, I could plug it into my amplifier, and carry on listening there.</p>
<p>There was no faff.  It didn&#39;t matter if I could find my favourite mix tape, or if my wifi was flakey - it was all just there.</p>
<p>Nowadays, when I&#39;m trying to pair my phone with some bluetooth speakers, or can&#39;t find my usb-to-headphone jack, or can&#39;t access my music because I don&#39;t have cellular reception; I feel like I&#39;ve taken a step back.</p>
<h3 id="the-web-audio-api">The Web Audio API</h3>
<p>I think the Web Audio API feels kind of like how my iPod did.</p>
<p>The Web Audio API looks different from other browser APIs.  Rather than throwing around data, or updating dom elements, you build a network of audio nodes, which the browser can use to generate/process/play sounds.</p>
<p>Let&#39;s take a look at it.  First of all, we want to get some music to play.  We can do this by creating an <code>&lt;audio&gt;</code> element.</p>
<pre><code class="lang-html">&lt;audio controls&gt;&lt;source blah /&gt;&lt;/audio&gt;
</code></pre>
<section class="ðŸ”ˆ">
  <audio src="night-owl.mp3" controls></audio>
</section>

<p>Song: <a href="http://freemusicarchive.org/music/Broke_For_Free/Directionless_EP/Broke_For_Free_-_Directionless_EP_-_01_Night_Owl">Night Owl by Broke For Free</a></p>
<p>Great! This works but it&#39;s playing directly through the browser rather than through using any the Web Audio API.</p>
<p>We can plug this element into our audio graph by using an <code>AudioSourceNode</code>.  This will capture the output from that element, and allow us to route it into whatever</p>
<p>This is cool, but it&#39;s playing <strong>directly through the browser</strong>; where we want to be able to control the audio through the Web Audio api. So the first thing we want to do is wire this into an audio graph.</p>
<p>We can do this by creating an AudioSourceNode - this wraps the output of the element, and allows us to feed the audio into a an audio graph.</p>
<pre><code class="lang-js">input = audioCtx.createAudioSourceNode(document.querySelector(&#39;audio&#39;))
input.connect(audioCtx.destination)
</code></pre>
<section class="ðŸ”ˆ" data-demo="basic">
  <audio src="night-owl.mp3" controls></audio>
</section>

<p>Cool.  This looks &amp; sounds exactly the same as before, though the difference is that it&#39;s running through the web audio api.</p>
<p>Now we can add some audio nodes to this graph and start doing some interesting stuff with it.</p>
<p><img src="images/graph-simple.svg" alt="Basic audio graph"></p>
<h2 id="gain">Gain</h2>
<p>First, we&#39;ll plug in a gain node - this allows you to alter the volume of an an audio stream.</p>
<pre><code class="lang-js">// &lt;input type=&quot;number&quot; min=0 max=1 step=0.01 id=&quot;volume&quot; /&gt;

gain = audioCtx.createGain()

volume.value = gain.gain.value
volume.oninput = () =&gt; gain.gain.value = parseFloat(volume.value)

input.connect(gain)
gain.connect(audioCtx.destination)
</code></pre>
<section class="ðŸ”ˆ" data-demo="gain">
  <audio src="night-owl.mp3" controls></audio>
  <input type="range" min=0 max=1 step=0.01 />
</section>

<p>You&#39;ll be able to see now that you can change the value of the input field, and the amplitude of the audio changes.</p>
<p>You can now hook this to any kind of interface that you want.</p>
<p><a href="https://uxdesign.cc/the-worst-volume-control-ui-in-the-world-60713dc86950">https://uxdesign.cc/the-worst-volume-control-ui-in-the-world-60713dc86950</a></p>
<p>So, now - our graph looks like this:</p>
<p><img src="images/graph-gain.svg" alt="(audio) -&gt; (gain) -&gt; (output)"></p>
<h2 id="analysers">Analysers</h2>
<p>An interesting node that we can use as an <em>Analyser</em> Node, this allows us to inspect the audio data that is flowing through our graph.</p>
<p>We can add an analyser node in the same way as we did the gain node, and it won&#39;t make any difference to the audio that god through it.</p>
<pre><code>analyser = audioCtx.createAnalyser

input.connect(analyser)
analyser.connect(gain)
gain.connect(audioCtx.destination)
</code></pre><p><img src="images/graph-gain.svg" alt="(audio) -&gt; (analyser) -&gt; (gain) -&gt; (output)"></p>
<p>Now, from elsewhere in our code, we can request data from the analyser node, and we&#39;ll get back an array that we can display in any way that we want.</p>
<pre><code class="lang-js">const waveform = new Uint8Array(analyser.fftSize)
const frequencies = new Uint8Array(analyser.frequencyBinCount)

const loop = () =&gt; {
    requestAnimationFrame(loop)
    analyser.getByteTimeDomainData(waveform)
    analyser.getByteFrequencyData(frequencies)

    // draw anything we want
}
loop()
</code></pre>
<p>The nice thing about this is that we&#39;re not tied to any functionality of the audio stream - it&#39;s completely up to us when we query the analyser node,  and we could feed it into anything we want.</p>
<p>For example, if we wanted to draw this data to a canvas, we could do it with the following code:</p>
<pre><code class="lang-js">ctx.beginPath()
waveform.forEach((f, i) =&gt; ctx.lineTo(i, f))
ctx.stroke()

ctx.beginPath()
frequencies.forEach((f, i) =&gt; ctx.lineTo(i, 255-f))
ctx.stroke()
</code></pre>
<section class="ðŸ”ˆ" data-demo="analyser">
  <audio src="night-owl.mp3" controls></audio>
  <input type="range" min=0 max=1 step=0.01 />
  <canvas width="700" height="300"></canvas>
  <!-- <div>
    <button>440hz</button>
  </div> -->
</section>

<p>[[audio, input, canvas]]</p>
<p>The two lines you can see here are:</p>
<ul>
<li>the waveform - this kind of plots air pressure against time</li>
<li>the frequencies - this shows the â€¦</li>
</ul>
<p>What&#39;s nice about this, is that you can plug it into whatever you want.  It could be a canvas, or webgl attributes, or updating elements, or even setting css variables.</p>
<h3 id="generating-audio">Generating Audio</h3>
<p>So far we&#39;ve used an <audio> element, though it&#39;s also possible to generate our own audio and feed it into our audio graph.</p>
<p>There&#39;s a few ways to do this, though the one we&#39;re going to look at is an AudioBufferNode.</p>
<p>This allows you to generate an array of samples (value at each timestamp), which you can then wrap up and play in exactly the same way we did the <audio> element before.</p>
<p>This can get a bit boring, so we&#39;ll use a helper method that will let us easily generate a sound:</p>
<pre><code class="lang-js">const generator = (audioCtx, target) =&gt; (seconds, fn) =&gt; {
  const { sampleRate } = audioCtx

  const buffer = audioCtx.createBuffer(
      1, sampleRate * seconds, sampleRate
  )
  const data = buffer.getChannelData(0)

  for (var i = 0; i &lt; data.length; i++) {
    data[i] = fn(i / sampleRate, seconds)
  }

  return () =&gt; {
    const source = audioCtx.createBufferSource()
    source.buffer = audioBuffer

    source.connect(target || audioCtx.destination)
    source.start()  
  }
}

const sound = generator(audioCtx)
</code></pre>
<p>Now we can write a function, that takes time, and maps it to a sample which we can then play through our browser.  For example, the following will generate 0.5 seconds of white noise at 20% volume (because, um, noise is a bitâ€¦ noisy?).</p>
<pre><code class="lang-js">const noise = sound(0.5, t =&gt; Math.random() * 0.2)
</code></pre>
<section class="ðŸ”ˆ" data-demo="buttonNoise">
  <div>
    <button>Noise</button>
  </div>
  <input type="range" min=0 max=1 step=0.01 />
  <canvas width="700" height="300"></canvas>
</section>

<p>Now, when we click that button, we&#39;ll hear a random noise from our speaker.  Very handy!</p>
<p>Our audio graph has changed a bit, rather than being static, every time we press a button, a new node is being created &amp; added, and being played through the speakers.</p>
<p>/ [buffer]   (source) =&gt; (analyser) =&gt; (gain) =&gt; (output)</p>
<p>The cool thing about this is that we can use this to generate all sorts of sounds and effects as mathematical functions.</p>
<p>For instance, we can build simple oscillator sounds:</p>
<pre><code class="lang-js">// Math.sin with period of 0..1
const sin = v =&gt; Math.sin(Math.PI * 2 * v)

const _440hz = sound(0.5, t =&gt; sin(t * 440))
const _880hz = sound(0.5, t =&gt; sin(t * 880))
</code></pre>
<section class="ðŸ”ˆ" data-demo="buttonHz">
  <div>
    <button data-hz="440">440Hz</button>
    <button data-hz="880">880Hz</button>
  </div>
  <input type="range" min=0 max=1 step=0.01 />
  <canvas width="700" height="300"></canvas>
</section>

<p>Since we&#39;re now expressing sounds as simple functions, we can start introducing higher order logic to implement new sounds &amp; effects.</p>
<p>For instance, if we want to have a richer, more harmonic, sound we can write a higher order function that combines multiple frequencies together:</p>
<pre><code>const harmony = f =&gt; [4, 3, 2, 1].reduce(
    (v, h, i) =&gt; (sin(f * h) * (i+1) ) + v
)

const a440 = sound(0.5, harmony(440))
</code></pre><section class="ðŸ”ˆ" data-demo="buttonHarmony">
  <div>
    <button data-hz="440">440Hz</button>
    <button data-hz="880">880Hz</button>
  </div>
  <input type="range" min=0 max=1 step=0.01 />
  <canvas width="700" height="300"></canvas>
</section>


<p>And because we&#39;re not using any audio-specific functionality here, we can repurpose anything that does an operation on data.</p>
<p>For instance, we can implement an ADSR envelope (which will make our note sound more like it&#39;s been pressed with a keyboard) with d3.</p>
<pre><code>const adsr = d3.scale()

const a440 = sound(0.5, (t, s) =&gt;
    harmony(440)(t) * adsr(s)
)
</code></pre><section class="ðŸ”ˆ" data-demo="buttonADSR">
  <div>
    <button data-hz="440">440Hz</button>
    <button data-hz="880">880Hz</button>
  </div>
  <input type="range" min=0 max=1 step=0.01 />
  <canvas width="700" height="300"></canvas>
</section>


<p>â€¦ Go and experiment yourself</p>
<p><a href="https://jsbin.com/tawenuh/edit?js,output">https://jsbin.com/tawenuh/edit?js,output</a></p>
<h3 id="-a-departure-from-best-practice-">(A departure from best practice)</h3>
<p>What we&#39;ve implemented with our manual function can actually be represented in a series of native audio nodes.</p>
<p>(oscillator) -&gt; (gain) -&gt; (destination)</p>
<p>Which will totally be more performant (because it&#39;s not happening on the main thread), and more flexible in some ways (because you can set timings dynamically whilst the note is playing).</p>
<p>But we&#39;re going to stay with this approach because it&#39;s fun, and sometimes the fun thing to do might not technically be the best.</p>
<ul>
<li>todo - &#39;from scratch&#39;</li>
</ul>
<h3 id="making-a-keyboard">Making a keyboard</h3>
<p>Having a button that makes a sound is totally great, but how about lots of buttons that make lots of sounds?  Yup, totally way-greater-er.</p>
<p>Because I&#39;m pretty terrible at CSS, I&#39;ve drawn an SVG image of a keyboard below:</p>
<section class="ðŸ”ˆ" data-demo="keyboard">
  <svg width="600" height="250" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><rect class="key" fill="#FFF" x="33" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="71.538" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="110.077" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="148.615" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="187.154" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="225.692" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="264.231" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="302.769" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="341.308" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="379.846" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="418.385" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="456.923" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="495.462" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#FFF" x="534" y="65" width="35" height="121" rx="4"/><rect class="key" fill="#383838" x="60" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="99" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="176" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="214" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="253" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="330" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="368" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="445" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="484" y="59" width="20" height="65" rx="4"/><rect class="key" fill="#383838" x="522" y="59" width="20" height="65" rx="4"/></g></svg>

  <canvas width="700" height="300"></canvas>
  <style>
    rect {stroke: #ddd;}
    rect:hover {opacity: 0.8; stroke: #000}
  </style>
</section>

<p>We can map the elements of this image, to different notes that we&#39;ve generated.  All we have to do is work out what frequency each of the notes should be.</p>
<p>I thought this would be hard because pianos were invented more than 250 years before the Hz unit was even defined, so surely there wouldn&#39;t be a simple mapping between the two?</p>
<pre><code>const freq = note =&gt; 27.5 * Math.pow(2, (note - 21) / 12)
</code></pre><p>This equation blows my mind.  It takes a midi note (each key on the keyboard is numbered), and returns the frequency of that note.</p>
<p>So now, we&#39;re able to hook up our SVG to the audio that we&#39;ve created:</p>
<pre><code>Array.from(svg.querySelector(&#39;rect&#39;))
    .sort((a, b) =&gt; a.cx - b.cx)
    .forEach((key, i) =&gt;
        key.addEventListener(&#39;touchstart&#39;,
            sound(0.5, (t, s) =&gt; adsr(s) * sin(freq(i) * t)
        )
    )
</code></pre><p>And, voilÃ . Our keyboard works:</p>
<p>[working keyboard]</p>
<p>Something that&#39;s kind of fun about this is that we can apply our code to any SVG at all and make a keyboard out of it.</p>
<p>[</p>
<h3 id="doing-better-in-the-future">Doing better in the future</h3>
<p>As I mentioned before, some of this could be implemented more performantly with WebAudio nodes,  or even better - you let something like Tone.js or Howler.js be performant for you.</p>
<p>There&#39;s also some new challenges with immersive WebXR experiences, where spatial audio becomes really important.  <a href="https://googlechrome.github.io/omnitone/#home">https://googlechrome.github.io/omnitone/#home</a></p>
<h3 id="conclusion">Conclusion</h3>
<p>And that&#39;s about it.</p>
<p>If anyone ever asks you &quot;could you turn this SVG into a musical instrument&quot; you don&#39;t have to stare blankly at them anymore.</p>
<p>If you&#39;re interested in the web audio api, there&#39;s heaps of information on MDN. There&#39;s also some interesting features coming up in the future (AudioWorklets look pretty cool).</p>
<p><a href="https://webaudio.github.io/web-audio-api/#AudioWorklet">https://webaudio.github.io/web-audio-api/#AudioWorklet</a></p>
<hr>
<p>Howler.js</p>
<hr>
<p>Ben Foxall is a JavaScript Engineer and Adventurist. After 16 years of avoiding the subject; he&#39;d like to tell Jamie that he probably did lose that mix-tape - he&#39;s sorry about, but also, he&#39;s not sure it was as good as Jamie made out.  Oh and also, Chris, sorry for breaking your phone, and that I still laugh every time I think about it.</p>



    <script type="text/javascript">
      (function(a,c){var b=a.createElement("script");if(!("noModule"in b)&&"on"+c in b){var d=!1;a.addEventListener(c,function(a){if(a.target===b)d=!0;else if(!a.target.hasAttribute("nomodule")||!d)return;a.preventDefault()},!0);b.type="module";b.src=".";a.head.appendChild(b);b.remove()}})(document,"beforeload");
    </script>
    <script defer src="https://d3js.org/d3.v4.min.js"></script>
    <script defer nomodule src="js/main.build.js"></script>
    <script type="module" src="js/main.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.9.0/prism.js"></script>
  </body>
</html>